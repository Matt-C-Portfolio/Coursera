{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5494b7fd-17e2-477e-bf58-954a48caf938",
   "metadata": {},
   "source": [
    "# NLP Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf10ea78-a0d1-401d-824e-25c0fbf37487",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561051a2-bfdd-4ce2-bf03-417f600875de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mattcarey/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab8c9532-e122-4d9b-88a5-ad0c2de57440",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'hello, school is almost over'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06bb5f76-0be4-41b6-ae9a-8196df907f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "741c772f-a79b-4d92-93b4-680946254bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', ',', 'school', 'is', 'almost', 'over']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b043cef5-812b-4afb-bae1-a19bec4a9f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mattcarey/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f32f16a-68e3-4876-86d9-a5afe3edfd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Hello, this is a wonderful day for all of us and for the rest of UNCC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02a106d8-4b5c-40b2-a08c-c0450f2cfa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'this', 'is', 'a', 'wonderful', 'day', 'for', 'all', 'of', 'us', 'and', 'for', 'the', 'rest', 'of', 'UNCC']\n"
     ]
    }
   ],
   "source": [
    "word_tokens = nltk.word_tokenize(text)\n",
    "print(word_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f78c1b02-27d9-4c1d-a2d7-17fe1c916193",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_without_stopwords = [word for word in word_tokens if not word in stopwords.words()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2d0854-7eda-48cf-9ba6-dec9f80cf76b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'wonderful', 'day', 'rest', 'UNCC']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_without_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86b5844-83e0-44d3-8023-4156e8c7b147",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1bdb7309-dd07-4ed6-bc52-b1c140907f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mattcarey/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a665e10-35c4-4eb7-86d4-e756a4812ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [ 'Compute', 'Computer', 'Computing', 'Computed', 'Computes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75741787-d4d0-4109-b1ae-16b8c9faea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1bbe092-1827-4c2b-b029-c30b0954253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comput\n",
      "comput\n",
      "comput\n",
      "comput\n",
      "comput\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    stem=ps.stem(word)\n",
    "    print(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c50c2da3-4a37-4127-b1a2-dd7e658d2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92c55a85-965d-423b-b895-00dcab42fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1f0fea0-13fe-4d3a-9e12-353df046bcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words= ['acts', 'acted', 'smiles', 'smile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf3c3f9c-a335-48b2-9198-891ffadd9c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act\n",
      "acted\n",
      "smile\n",
      "smile\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    lem = wordnet_lemmatizer.lemmatize(word)\n",
    "    print(lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70964c91-5ba3-44f1-9d3d-ffe312de8b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
